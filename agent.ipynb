{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f42eae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AnyMessage,\n",
    "    HumanMessage,\n",
    "    RemoveMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56369199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6df2a0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0.7, max_retries=3, output_version=\"responses/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e28a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "\n",
    "You are an expert on Python Data Science and Machine Learning code generation. Here are the rules \n",
    "you must follow when generating code:\n",
    "\n",
    "- Return only code, no preembale or postamble.\n",
    "- Code should be Python3 unless stated otherwise. \n",
    "- Any comments or explanations should be inline with the code.\n",
    "- Only use Python Standard library, Numpy, Matplotlib, Pandas, Scikit-Learn and Pytorch\n",
    "- Avoid using third-party packages, when in doubt, ask.\n",
    "- Code should be complete and fully runnable\n",
    "- Code should be PEP8 compliant\n",
    "- Code, classes, function and methods should have complete Docstrings.\n",
    "- Beautiful is better than ugly.\n",
    "- Explicit is better than implicit.\n",
    "- Simple is better than complex.\n",
    "- Readability counts.\n",
    "- In the face of ambiguity, refuse the temptation to guess.\n",
    "- If the implementation is hard to explain, it's a bad idea.\n",
    "- If the implementation is easy to explain, it may be a good idea. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71662078",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = (\n",
    "    [\n",
    "        {\"type\": \"code_interpreter\", \"container\": {\"type\": \"auto\"}},\n",
    "        {\"type\": \"web_search_preview\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d556b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "\n",
    "def parse_dataframe_info(info_output: str) -> str:\n",
    "    \"\"\"\n",
    "    Parse the string output of DataFrame.info() into a JSON object.\n",
    "    \n",
    "    This function extracts column information from pandas DataFrame.info() output,\n",
    "    ignoring the header lines and footer statistics. It focuses only on parsing\n",
    "    the column details including index, name, non-null count, and data type.\n",
    "    \n",
    "    Args:\n",
    "        info_output (str): The string output from DataFrame.info()\n",
    "        \n",
    "    Returns:\n",
    "        str: JSON string containing parsed column information\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the input format is not recognized or cannot be parsed\n",
    "    \"\"\"\n",
    "    lines = info_output.strip().split('\\n')\n",
    "    columns_data = []\n",
    "    \n",
    "    # Find the start of column data (skip first 3 lines)\n",
    "    column_start_index = 3\n",
    "    \n",
    "    # Find where column data ends (before dtypes: or memory usage:)\n",
    "    column_end_index = len(lines)\n",
    "    for i, line in enumerate(lines[column_start_index:], column_start_index):\n",
    "        if line.strip().startswith('dtypes:') or line.strip().startswith('memory usage:'):\n",
    "            column_end_index = i\n",
    "            break\n",
    "    \n",
    "    # Parse each column line\n",
    "    for line in lines[column_start_index:column_end_index]:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Skip separator lines (lines with only dashes and spaces)\n",
    "        if re.match(r'^[-\\s]+$', line) or not line:\n",
    "            continue\n",
    "            \n",
    "        # Parse column information using regex\n",
    "        # Pattern matches: index, column_name, non_null_count, dtype\n",
    "        pattern = r'^\\s*(\\d+)\\s+(\\S+)\\s+(\\d+)\\s+non-null\\s+(\\S+)\\s*$'\n",
    "        match = re.match(pattern, line)\n",
    "        \n",
    "        if match:\n",
    "            column_index = int(match.group(1))\n",
    "            column_name = match.group(2)\n",
    "            non_null_count = int(match.group(3))\n",
    "            dtype = match.group(4)\n",
    "            \n",
    "            column_info = {\n",
    "                'index': column_index,\n",
    "                'column_name': column_name,\n",
    "                'non_null_count': non_null_count,\n",
    "                'dtype': dtype\n",
    "            }\n",
    "            \n",
    "            columns_data.append(column_info)\n",
    "    \n",
    "    # Create the final JSON structure\n",
    "    result = {\n",
    "        'columns': columns_data,\n",
    "        'total_columns': len(columns_data)\n",
    "    }\n",
    "    \n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "\n",
    "def parse_dataframe_info_to_dict(info_output: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse the string output of DataFrame.info() into a Python dictionary.\n",
    "    \n",
    "    This function is similar to parse_dataframe_info() but returns a dictionary\n",
    "    instead of a JSON string, which can be more convenient for further processing.\n",
    "    \n",
    "    Args:\n",
    "        info_output (str): The string output from DataFrame.info()\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, Any]: Dictionary containing parsed column information\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the input format is not recognized or cannot be parsed\n",
    "    \"\"\"\n",
    "    json_string = parse_dataframe_info(info_output)\n",
    "    return json.loads(json_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e3ae83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "df = pd.read_csv(\"assets/simpsons_episodes.csv\")\n",
    "buffer = io.StringIO()\n",
    "df.info(buf=buffer, show_counts=True, memory_usage=\"deep\")\n",
    "df_json = parse_dataframe_info_to_dict(buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d0eef28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(\n",
    "    content=system_prompt,\n",
    ")\n",
    "\n",
    "human_message = HumanMessage(\n",
    "    content=\"Provide Python code that will rank the episodes by US viewers and plot the top 10 episodes.\" \\\n",
    "    \"Assume the dataframe has been loaded and is available as `df`.\",\n",
    "    additional_kwargs={\"structure of Dataframe\": json.dumps(df_json, indent=2)})\n",
    "\n",
    "messages = [system_message, human_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa4807da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CodeResponse(BaseModel):\n",
    "    code: str = Field(description=\"The setup of the joke\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92254f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(schema=CodeResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "336fe2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = structured_llm.invoke(messages, tools=tools[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d64a9567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "\n",
      "def plot_top_10_episodes_by_us_viewers(df: pd.DataFrame) -> None:\n",
      "    \"\"\"\n",
      "    Ranks episodes by US viewers and plots the top 10 episodes.\n",
      "    Assumes 'US_viewers' and 'episode' columns exist in df.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    df : pd.DataFrame\n",
      "        DataFrame containing 'US_viewers' and 'episode' columns.\n",
      "    \"\"\"\n",
      "    # Ensure the required columns exist\n",
      "    if 'US_viewers' not in df.columns or 'episode' not in df.columns:\n",
      "        raise ValueError(\"DataFrame must contain 'US_viewers' and 'episode' columns.\")\n",
      "\n",
      "    # Sort episodes by 'US_viewers' in descending order and select top 10\n",
      "    top_episodes = df.sort_values('US_viewers', ascending=False).head(10)\n",
      "\n",
      "    # Plot\n",
      "    plt.figure(figsize=(10, 6))\n",
      "    plt.barh(top_episodes['episode'][::-1], top_episodes['US_viewers'][::-1], color='skyblue')\n",
      "    plt.xlabel('US Viewers (millions)')\n",
      "    plt.title('Top 10 Episodes by US Viewers')\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "# Example usage:\n",
      "# plot_top_10_episodes_by_us_viewers(df)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resp.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc90766",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e4987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
