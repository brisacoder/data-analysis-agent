{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daa7e5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path from JSON: data/InfiAgent-DABench/da-dev-tables/abalone.csv\n",
      "Path object: data\\InfiAgent-DABench\\da-dev-tables\\abalone.csv\n",
      "Path exists: True\n",
      "With native separators: data\\\\InfiAgent-DABench\\\\da-dev-tables\\\\abalone.csv\n",
      "\\nKey points:\n",
      "✓ Windows accepts forward slashes\n",
      "✓ Path() works with forward slashes\n",
      "✓ No conversion needed when reading from JSON\n"
     ]
    }
   ],
   "source": [
    "# Windows handles forward slashes correctly in file paths\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Simulate what happens when you read from JSON\n",
    "json_data = '{\"file_name\": \"data/InfiAgent-DABench/da-dev-tables/abalone.csv\"}'\n",
    "loaded = json.loads(json_data)\n",
    "file_path_from_json = loaded[\"file_name\"]\n",
    "\n",
    "print(f\"Path from JSON: {file_path_from_json}\")\n",
    "\n",
    "# Convert to Path object - works fine with forward slashes\n",
    "path_obj = Path(file_path_from_json)\n",
    "print(f\"Path object: {path_obj}\")\n",
    "print(f\"Path exists: {path_obj.exists()}\")\n",
    "\n",
    "# If you need native Windows separators, you can get them\n",
    "print(f\"With native separators: {path_obj.as_posix().replace('/', '\\\\\\\\')}\")\n",
    "\n",
    "print(\"\\\\nKey points:\")\n",
    "print(\"✓ Windows accepts forward slashes\")\n",
    "print(\"✓ Path() works with forward slashes\") \n",
    "print(\"✓ No conversion needed when reading from JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd6bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "questions = Path(os.getenv(\"QUESTIONS_FILE\"))\n",
    "answers = Path(os.getenv(\"ANSWERS_FILE\"))\n",
    "# df_json = pd.read_json(questions, lines=True).to_dict(orient='records')\n",
    "df_questions = pd.read_json(questions, lines=True)\n",
    "df_answers = pd.read_json(answers, lines=True)\n",
    "df_merged = df_answers.merge(df_questions, left_on=\"id\", right_on=\"id\", how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c1e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from dataframe_to_dict import parse_dataframe_info\n",
    "\n",
    "def df_info_to_json(df):\n",
    "    buffer = io.StringIO()\n",
    "    df.info(buf=buffer, show_counts=True)\n",
    "    df_json = parse_dataframe_info(buffer.getvalue())\n",
    "    return df_json    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26720fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from planner import create_plan\n",
    "\n",
    "path_prefix = Path(\"data/InfiAgent-DABench/da-dev-tables/\")\n",
    "for index, row in df_merged.iterrows():\n",
    "    file_name = path_prefix / row['file_name']\n",
    "    df = pd.read_csv(file_name)\n",
    "    df_json = df_info_to_json(df)\n",
    "    plan = create_plan(row['question'], df_json, file_name)\n",
    "    df_merged.at[index, 'plan'] = plan.model_dump_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f00629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"data/merged_with_plans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44221fef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error invoking model: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dev\\Dropbox\\GitHub\\data-analysis-agent\\coder.py:123\u001b[39m, in \u001b[36mCodeGenerator.create_code\u001b[39m\u001b[34m(self, plan, question, df_json, data_file_name)\u001b[39m\n\u001b[32m    122\u001b[39m json_str = json_str.replace(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[33m'\u001b[39m).replace(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m parsed_data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m resp = CodeResponse(**parsed_data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\json\\decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\json\\decoder.py:361\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m df = pd.read_csv(file_name)\n\u001b[32m      7\u001b[39m df_json = df_info_to_json(df)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m code = \u001b[43mcreate_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mplan\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfile_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m df_merged.at[index, \u001b[33m'\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m'\u001b[39m] = code.model_dump_json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dev\\Dropbox\\GitHub\\data-analysis-agent\\coder.py:169\u001b[39m, in \u001b[36mcreate_code\u001b[39m\u001b[34m(plan, question, df_json, data_file_name)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_code\u001b[39m(plan: \u001b[38;5;28mstr\u001b[39m, question: \u001b[38;5;28mstr\u001b[39m, df_json: \u001b[38;5;28mstr\u001b[39m, data_file_name: Path) -> CodeResponse:\n\u001b[32m    157\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[33;03m    Generate Python code based on a data analysis plan and question.\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    This function maintains backward compatibility by delegating to the CodeGenerator singleton.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m \u001b[33;03m        CodeResponse: Structured response containing the generated code and metadata\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_code_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_file_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dev\\Dropbox\\GitHub\\data-analysis-agent\\coder.py:133\u001b[39m, in \u001b[36mCodeGenerator.create_code\u001b[39m\u001b[34m(self, plan, question, df_json, data_file_name)\u001b[39m\n\u001b[32m    127\u001b[39m             resp = CodeResponse(\n\u001b[32m    128\u001b[39m                 code=raw_content,\n\u001b[32m    129\u001b[39m                 assumptions=[\u001b[33m\"\u001b[39m\u001b[33mGenerated from raw LLM output due to JSON parsing issues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    130\u001b[39m             )\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError invoking model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Ensure directory is ready (clean only on first use)\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Error invoking model: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "from coder import create_code\n",
    "\n",
    "path_prefix = Path(\"data/InfiAgent-DABench/da-dev-tables/\")\n",
    "for index, row in df_merged.iterrows():\n",
    "    file_name = path_prefix / row['file_name']\n",
    "    df = pd.read_csv(file_name)\n",
    "    df_json = df_info_to_json(df)\n",
    "    code = create_code(row['plan'], row['question'], df_json, Path(row['file_name']))\n",
    "    df_merged.at[index, 'code'] = code.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b43ad021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"data/merged_with_code.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ccb090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
