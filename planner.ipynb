{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f11693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AnyMessage,\n",
    "    HumanMessage,\n",
    "    RemoveMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4669bb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ebb4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from dataframe_to_dict import parse_dataframe_info_to_dict\n",
    "\n",
    "df = pd.read_csv(os.getenv(\"PROCESSED_DATA_FILE\"))\n",
    "buffer = io.StringIO()\n",
    "df.info(buf=buffer, show_counts=True)\n",
    "df_json = parse_dataframe_info_to_dict(buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3793c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_system_prompt = \"\"\"\n",
    "You are the Planner Agent for a Python Data Science and Machine Learning coding assistant. \n",
    "Your job is to create a structured coding plan to ensure no part of the user request is overlooked. \n",
    "\n",
    "You do NOT write code. You ONLY produce a plan for the Coding Agent to implement.\n",
    "\n",
    "Allowed libraries: Python standard library, NumPy, Pandas, Matplotlib, Scikit-Learn.\n",
    "\n",
    "PLAN REQUIREMENTS\n",
    "-----------------\n",
    "1. Each plan must decompose the user’s request into discrete, ordered tasks.\n",
    "2. Tasks must be sequential, unambiguous, and self-contained.\n",
    "3. If any data is needed but not clearly provided:\n",
    "   - Assume it is in a CSV file.\n",
    "   - Include a **first task** to load it using Pandas.\n",
    "   - Assign a reasonable default filename like `data.csv` unless one is specified.\n",
    "4. If something is ambiguous, do NOT ask the user.\n",
    "   - State your assumptions clearly in the task’s description.\n",
    "\n",
    "You must not skip or merge tasks unless explicitly redundant.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22815773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Task(BaseModel):\n",
    "    task_name: str = Field(description=\"Short description of the coding task.\")\n",
    "    details: str = Field(description=\"Step-by-step description of what must be done, including any transformations or conditions.\")\n",
    "    dependencies: str = Field(description=\"Data or previous tasks this step depends on.\")\n",
    "    output: str = Field(description=\"What this task should produce.\")\n",
    "    assumptions: str = Field(description=\"Any assumptions made to proceed with the task, especially if the user request was unclear.\")\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    task_list : List[Task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c081b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "\n",
    "with open(os.getenv('QUESTIONS_FILE')) as f:\n",
    "    questions = [json.loads(line)['question'] for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c985880e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Perform a distribution analysis on the 'Fare' column for each passenger class ('Pclass') separately. Calculate the mean, median, and standard deviation of the fare for each class. Interpret the results in terms of the different passenger classes.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49a32a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(\n",
    "    content=planner_system_prompt,\n",
    ")\n",
    "\n",
    "df_structure = \"DataFrame Structure:\\n\" + json.dumps(df_json, indent=2)\n",
    "\n",
    "human_message = HumanMessage(\n",
    "    content=questions[0] + \"\\n\\n\"\n",
    "      + df_structure)\n",
    "    \n",
    "messages = [system_message, human_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7091ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0.7, max_retries=3, output_version=\"responses/v1\")\n",
    "structured_llm = llm.with_structured_output(schema=Plan)\n",
    "resp = structured_llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1336079",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"planner_output.json\", \"w\") as f:\n",
    "    json.dump(resp.model_dump(), f, indent=2)  # Save the structured response to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0463c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
