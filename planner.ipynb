{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35f11693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AnyMessage,\n",
    "    HumanMessage,\n",
    "    RemoveMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4669bb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b05c651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def parse_dataframe_info(info_output: str) -> str:\n",
    "    \"\"\"\n",
    "    Parse the string output of DataFrame.info() into a JSON object.\n",
    "    \n",
    "    This function extracts column information from pandas DataFrame.info() output,\n",
    "    ignoring the header lines and footer statistics. It focuses only on parsing\n",
    "    the column details including index, name, non-null count, and data type.\n",
    "    \n",
    "    Args:\n",
    "        info_output (str): The string output from DataFrame.info()\n",
    "        \n",
    "    Returns:\n",
    "        str: JSON string containing parsed column information\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the input format is not recognized or cannot be parsed\n",
    "    \"\"\"\n",
    "    lines = info_output.strip().split('\\n')\n",
    "    columns_data = []\n",
    "    \n",
    "    # Find the start of column data (skip first 3 lines)\n",
    "    column_start_index = 3\n",
    "    \n",
    "    # Find where column data ends (before dtypes: or memory usage:)\n",
    "    column_end_index = len(lines)\n",
    "    for i, line in enumerate(lines[column_start_index:], column_start_index):\n",
    "        if line.strip().startswith('dtypes:') or line.strip().startswith('memory usage:'):\n",
    "            column_end_index = i\n",
    "            break\n",
    "    \n",
    "    # Parse each column line\n",
    "    for line in lines[column_start_index:column_end_index]:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Skip separator lines (lines with only dashes and spaces)\n",
    "        if re.match(r'^[-\\s]+$', line) or not line:\n",
    "            continue\n",
    "            \n",
    "        # Parse column information using regex\n",
    "        # Pattern matches: index, column_name, non_null_count, dtype\n",
    "        pattern = r'^\\s*(\\d+)\\s+(\\S+)\\s+(\\d+)\\s+non-null\\s+(\\S+)\\s*$'\n",
    "        match = re.match(pattern, line)\n",
    "        \n",
    "        if match:\n",
    "            column_index = int(match.group(1))\n",
    "            column_name = match.group(2)\n",
    "            non_null_count = int(match.group(3))\n",
    "            dtype = match.group(4)\n",
    "            \n",
    "            column_info = {\n",
    "                'index': column_index,\n",
    "                'column_name': column_name,\n",
    "                'non_null_count': non_null_count,\n",
    "                'dtype': dtype\n",
    "            }\n",
    "            \n",
    "            columns_data.append(column_info)\n",
    "    \n",
    "    # Create the final JSON structure\n",
    "    result = {\n",
    "        'columns': columns_data,\n",
    "        'total_columns': len(columns_data)\n",
    "    }\n",
    "    \n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "\n",
    "def parse_dataframe_info_to_dict(info_output: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse the string output of DataFrame.info() into a Python dictionary.\n",
    "    \n",
    "    This function is similar to parse_dataframe_info() but returns a dictionary\n",
    "    instead of a JSON string, which can be more convenient for further processing.\n",
    "    \n",
    "    Args:\n",
    "        info_output (str): The string output from DataFrame.info()\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, Any]: Dictionary containing parsed column information\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the input format is not recognized or cannot be parsed\n",
    "    \"\"\"\n",
    "    json_string = parse_dataframe_info(info_output)\n",
    "    return json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ebb4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "df = pd.read_csv(\"curated/DEVRT-DACIA-SPRING.csv\")\n",
    "buffer = io.StringIO()\n",
    "df.info(buf=buffer, show_counts=True)\n",
    "df_json = parse_dataframe_info_to_dict(buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3793c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_system_prompt = \"\"\"\n",
    "You are the Planner Agent for a Python Data Science and Machine Learning coding assistant. \n",
    "Your job is to create a structured coding plan to ensure no part of the user request is overlooked. \n",
    "\n",
    "- You do not write code. \n",
    "- You only produce a plan for the Coding Agent to implement.\n",
    "- Each plan must cover every part of the user request as discrete tasks.\n",
    "- Tasks should be sequential and unambiguous.\n",
    "- If the user request is unclear or ambiguous, flag which tasks require clarification.\n",
    "- Include input requirements and expected outputs for each task if applicable.\n",
    "- Your output should be in a structured format that is easy for a Coding Agent to follow.\n",
    "\n",
    "Do not skip any part of the userâ€™s request.\n",
    "Do not make assumptions that are not explicitly stated.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22815773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Task(BaseModel):\n",
    "    task_name: str = Field(description=\"Short description of the coding task.\")\n",
    "    details: str = Field(description=\"Step-by-step description of what must be done, including any transformations or conditions.\")\n",
    "    dependencies: str = Field(description=\"Data or previous tasks this step depends on.\")\n",
    "    output: str = Field(description=\"What this task should produce.\")\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    task_list : List[Task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "310e385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0.7, max_retries=3, output_version=\"responses/v1\")\n",
    "structured_llm = llm.with_structured_output(schema=Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49a32a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(\n",
    "    content=planner_system_prompt,\n",
    ")\n",
    "\n",
    "human_message = HumanMessage(\n",
    "    content=\"What is the correlation coefficient between altitude and average speed? Fill missing values with column mean.\"\n",
    "    \"Calculate Pearson correlation between 'altitude' and 'speedAvg' columns. Round to 3 decimal places. Expect single numerical value else \" \\\n",
    "    \"Assume the dataframe has been loaded and is available as `df`.\" \\\n",
    "    \"Structured of the DataFrame:\\n\" +\n",
    "    json.dumps(df_json, indent=2))\n",
    "messages = [system_message, human_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7091ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = structured_llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1336079",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"planner_output.json\", \"w\") as f:\n",
    "    json.dump(resp.model_dump(), f, indent=2)  # Save the structured response to a file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
