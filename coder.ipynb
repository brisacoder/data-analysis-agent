{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f42eae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AnyMessage,\n",
    "    HumanMessage,\n",
    "    RemoveMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56369199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e28a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coder_system_prompt = \"\"\"\n",
    "You are the Coding Agent in a two-stage pipeline (Planner ➜ Coder).\n",
    "\n",
    "INPUT\n",
    "------\n",
    "You will receive:\n",
    "1. A “Coding Plan” produced by the Planner Agent.\n",
    "   • It is an ordered list of numbered tasks.  \n",
    "   • Each task contains: Task Name, Details, Dependencies, Output.\n",
    "2. The original user request (for reference only).\n",
    "3. The structure of the DataFrame to be used in the tasks. This is the output of Pandas' `df.info()` method\n",
    "\n",
    "OBJECTIVE\n",
    "---------\n",
    "Write a **single, fully-runnable Python 3 script** that accomplishes *all* tasks in the Coding Plan, in order, without omission.\n",
    "\n",
    "STRICT RULES\n",
    "------------\n",
    "- **Return only code** – no prose, comments outside the script, or explanations.\n",
    "- The script must be PEP 8 compliant, self-contained, and ready to run.\n",
    "- Allowed libraries: Python standard library, NumPy, Pandas, Matplotlib, Scikit-Learn, PyTorch.\n",
    "- If a task requires plotting, save figures to files (do not display).\n",
    "- Insert clear inline comments and complete docstrings for every function, class, or complex section.\n",
    "- If the plan specifies an output file name (e.g., “top_10_customers.png”), save exactly that name.\n",
    "- Respect all user constraints from the original request.\n",
    "- **Never ignore or reorder tasks** unless an explicit dependency forces you to combine steps.\n",
    "- If the plan references data that is undefined (e.g., missing column names), raise a clear\n",
    "  `ValueError` in the code rather than guessing.\n",
    "- If any task is impossible with the permitted libraries, stop and raise\n",
    "  `NotImplementedError` inside the script, citing the task name.\n",
    "\n",
    "IMPLEMENTATION GUIDELINES\n",
    "-------------------------\n",
    "- Begin with all necessary imports.\n",
    "- Encapsulate each task in a well-named function whose docstring mirrors the task description.\n",
    "- Provide a `main()` function that calls task-functions in the correct order and writes/prints\n",
    "  the final results as specified.\n",
    "- Use type hints where helpful for readability.\n",
    "- Place the customary `if __name__ == \"__main__\": main()` guard at the end.\n",
    "\n",
    "FAIL-SAFE\n",
    "---------\n",
    "If you detect that the Coding Plan itself is ambiguous or missing critical information,\n",
    "raise a `ValueError` at the top of the script explaining which task needs clarification.\n",
    "\n",
    "OUTPUT FORMAT\n",
    "-------------\n",
    "Return the complete Python script **and nothing else**.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71662078",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = (\n",
    "    [\n",
    "        {\"type\": \"code_interpreter\", \"container\": {\"type\": \"auto\"}},\n",
    "        {\"type\": \"web_search_preview\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e3ae83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from dataframe_to_dict import parse_dataframe_info_to_dict\n",
    "\n",
    "df = pd.read_csv(os.getenv(\"PROCESSED_DATA_FILE\"))\n",
    "buffer = io.StringIO()\n",
    "df.info(buf=buffer, show_counts=True)\n",
    "df_json = parse_dataframe_info_to_dict(buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc1180dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = \"\"\n",
    "with open(\"planner_output.json\", \"r\") as f:\n",
    "    plan = f.read()  # Save the parsed DataFrame info to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acf85a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "\n",
    "with open(os.getenv('QUESTIONS_FILE')) as f:\n",
    "    questions = [json.loads(line)['question'] for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7647da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(\n",
    "    content=coder_system_prompt,\n",
    ")\n",
    "\n",
    "df_structure = \"DataFrame Structure:\\n\" + json.dumps(df_json, indent=2)\n",
    "\n",
    "plan = \"Plan: \"\n",
    "with open(\"planner_output.json\", \"r\") as f:\n",
    "    plan += f.read()\n",
    "\n",
    "original_request = questions[5]  # Assuming the original request is the 5th question\n",
    "\n",
    "human_message = HumanMessage(\n",
    "    content=plan + \"\\n\\n\"\n",
    "    + \"Human Request:\\n\" + original_request + \"\\n\\n\"\n",
    "    + df_structure)\n",
    "    \n",
    "messages = [system_message, human_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa4807da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CodeResponse(BaseModel):\n",
    "    code: str = Field(description=\"The Python code to execute the task.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92254f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0.7, max_retries=3, output_version=\"responses/v1\")\n",
    "structured_llm = llm.with_structured_output(schema=CodeResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "336fe2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = structured_llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d64a9567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from typing import Tuple, Optional\n",
      "\n",
      "def load_data(file_path: str) -> pd.DataFrame:\n",
      "    \"\"\"\n",
      "    Load the dataset from a CSV file named 'data.csv' into a Pandas DataFrame.\n",
      "    \"\"\"\n",
      "    df = pd.read_csv(file_path)\n",
      "    if 'speedAvg' not in df.columns or 'soh' not in df.columns:\n",
      "        raise ValueError(\"Missing required columns: 'speedAvg' or 'soh' in the data.\")\n",
      "    return df\n",
      "\n",
      "def fill_missing_speedavg(df: pd.DataFrame) -> pd.DataFrame:\n",
      "    \"\"\"\n",
      "    Identify missing values in the 'speedAvg' column and replace them with the mean value of the non-missing 'speedAvg' entries.\n",
      "    \"\"\"\n",
      "    if 'speedAvg' not in df.columns:\n",
      "        raise ValueError(\"Column 'speedAvg' not found in DataFrame.\")\n",
      "    mean_speed = df['speedAvg'].mean(skipna=True)\n",
      "    df['speedAvg'] = df['speedAvg'].fillna(mean_speed)\n",
      "    return df\n",
      "\n",
      "def create_speed_bins(df: pd.DataFrame) -> pd.DataFrame:\n",
      "    \"\"\"\n",
      "    Create a new categorical column in the DataFrame named 'speed_bin' based on the following intervals of 'speedAvg':\n",
      "    0-50, 50-80, 80-100, 100+ km/h. Use intervals: [0, 50), [50, 80), [80, 100), [100, inf).\n",
      "    \"\"\"\n",
      "    if 'speedAvg' not in df.columns:\n",
      "        raise ValueError(\"Column 'speedAvg' not found in DataFrame.\")\n",
      "    bins = [0, 50, 80, 100, np.inf]\n",
      "    labels = ['0-50', '50-80', '80-100', '100+']\n",
      "    df['speed_bin'] = pd.cut(df['speedAvg'], bins=bins, labels=labels, right=False, include_lowest=True)\n",
      "    return df\n",
      "\n",
      "def calculate_average_soh_by_bin(df: pd.DataFrame) -> pd.DataFrame:\n",
      "    \"\"\"\n",
      "    Group the DataFrame by 'speed_bin' and calculate the average 'soh' for each bin. Round the resulting average SOH values to two decimal places.\n",
      "    \"\"\"\n",
      "    if 'speed_bin' not in df.columns or 'soh' not in df.columns:\n",
      "        raise ValueError(\"Columns 'speed_bin' or 'soh' not found in DataFrame.\")\n",
      "    soh_by_bin = df.groupby('speed_bin', observed=True)['soh'].mean().round(2).reset_index()\n",
      "    soh_by_bin = soh_by_bin.dropna(subset=['speed_bin'])\n",
      "    soh_by_bin = soh_by_bin.loc[soh_by_bin['soh'].notna()]\n",
      "    return soh_by_bin\n",
      "\n",
      "def find_optimal_speed_bin(soh_by_bin: pd.DataFrame) -> str:\n",
      "    \"\"\"\n",
      "    Identify the speed bin with the highest average SOH. If there is a tie, select the first such bin in order. If no bins exist, return an empty string.\n",
      "    \"\"\"\n",
      "    if soh_by_bin.empty or 'soh' not in soh_by_bin.columns or 'speed_bin' not in soh_by_bin.columns:\n",
      "        return ''\n",
      "    max_soh = soh_by_bin['soh'].max()\n",
      "    bins_with_max_soh = soh_by_bin.loc[soh_by_bin['soh'] == max_soh, 'speed_bin']\n",
      "    if bins_with_max_soh.empty:\n",
      "        return ''\n",
      "    return str(bins_with_max_soh.iloc[0])\n",
      "\n",
      "def main() -> None:\n",
      "    df = load_data('data.csv')\n",
      "    df = fill_missing_speedavg(df)\n",
      "    df = create_speed_bins(df)\n",
      "    soh_by_bin = calculate_average_soh_by_bin(df)\n",
      "    optimal_bin = find_optimal_speed_bin(soh_by_bin)\n",
      "    print(optimal_bin)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resp.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the dataset from a CSV file named 'data.csv' into a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'speedAvg' not in df.columns or 'soh' not in df.columns:\n",
    "        raise ValueError(\"Missing required columns: 'speedAvg' or 'soh' in the data.\")\n",
    "    return df\n",
    "\n",
    "def fill_missing_speedavg(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identify missing values in the 'speedAvg' column and replace them with the mean value of the non-missing 'speedAvg' entries.\n",
    "    \"\"\"\n",
    "    if 'speedAvg' not in df.columns:\n",
    "        raise ValueError(\"Column 'speedAvg' not found in DataFrame.\")\n",
    "    mean_speed = df['speedAvg'].mean(skipna=True)\n",
    "    df['speedAvg'] = df['speedAvg'].fillna(mean_speed)\n",
    "    return df\n",
    "\n",
    "def create_speed_bins(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a new categorical column in the DataFrame named 'speed_bin' based on the following intervals of 'speedAvg':\n",
    "    0-50, 50-80, 80-100, 100+ km/h. Use intervals: [0, 50), [50, 80), [80, 100), [100, inf).\n",
    "    \"\"\"\n",
    "    if 'speedAvg' not in df.columns:\n",
    "        raise ValueError(\"Column 'speedAvg' not found in DataFrame.\")\n",
    "    bins = [0, 50, 80, 100, np.inf]\n",
    "    labels = ['0-50', '50-80', '80-100', '100+']\n",
    "    df['speed_bin'] = pd.cut(df['speedAvg'], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "    return df\n",
    "\n",
    "def calculate_average_soh_by_bin(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Group the DataFrame by 'speed_bin' and calculate the average 'soh' for each bin. Round the resulting average SOH values to two decimal places.\n",
    "    \"\"\"\n",
    "    if 'speed_bin' not in df.columns or 'soh' not in df.columns:\n",
    "        raise ValueError(\"Columns 'speed_bin' or 'soh' not found in DataFrame.\")\n",
    "    soh_by_bin = df.groupby('speed_bin', observed=True)['soh'].mean().round(2).reset_index()\n",
    "    soh_by_bin = soh_by_bin.dropna(subset=['speed_bin'])\n",
    "    soh_by_bin = soh_by_bin.loc[soh_by_bin['soh'].notna()]\n",
    "    return soh_by_bin\n",
    "\n",
    "def find_optimal_speed_bin(soh_by_bin: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Identify the speed bin with the highest average SOH. If there is a tie, select the first such bin in order. If no bins exist, return an empty string.\n",
    "    \"\"\"\n",
    "    if soh_by_bin.empty or 'soh' not in soh_by_bin.columns or 'speed_bin' not in soh_by_bin.columns:\n",
    "        return ''\n",
    "    max_soh = soh_by_bin['soh'].max()\n",
    "    bins_with_max_soh = soh_by_bin.loc[soh_by_bin['soh'] == max_soh, 'speed_bin']\n",
    "    if bins_with_max_soh.empty:\n",
    "        return ''\n",
    "    return str(bins_with_max_soh.iloc[0])\n",
    "\n",
    "def main() -> None:\n",
    "    df = load_data('data.csv')\n",
    "    df = fill_missing_speedavg(df)\n",
    "    df = create_speed_bins(df)\n",
    "    soh_by_bin = calculate_average_soh_by_bin(df)\n",
    "    optimal_bin = find_optimal_speed_bin(soh_by_bin)\n",
    "    print(optimal_bin)\n",
    "\n",
    "\n",
    "main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
